{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study Note - Building AI Solutions with Azure Machine Learning\n",
    "This notebook collects the notes taken through the course of **[Build AI solutions with Azure Machine Learning](https://docs.microsoft.com/en-us/learn/paths/build-ai-solutions-with-azure-ml-service/)** offered by Microsoft, with supplements from the **[documentation of Azure Machine Learning SDK for Python](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guideline vs Learning Sections\n",
    "\n",
    "### Set up an Azure Machine Learning Workspace (30-35%)\n",
    "\n",
    "#### Create an Azure Machine Learning workspace (Lab 01)\n",
    "- create an Azure Machine Learning workspace\n",
    "- configure workspace settings\n",
    "- manage a workspace by using Azure Machine Learning studio\n",
    "\n",
    "#### Manage data objects in an Azure Machine Learning workspace (Lab 03)\n",
    "- register and maintain data stores\n",
    "- create and manage datasets\n",
    "\n",
    "#### Manage experiment compute contexts (Lab 01 & 04)\n",
    "- create a compute instance\n",
    "- determine appropriate compute specifications for a training workload\n",
    "- create compute targets for experiments and training\n",
    "\n",
    "### Run Experiments and Train Models (25-30%)\n",
    "\n",
    "#### Create models by using Azure Machine Learning Designer (Create no-code predictive models with Azure Machine Learning)\n",
    "- create a training pipeline by using Azure Machine Learning designer\n",
    "- ingest data in a designer pipeline\n",
    "- use designer modules to define a pipeline data flow\n",
    "- use custom code modules in designer\n",
    "\n",
    "#### Run training scripts in an Azure Machine Learning workspace (Lab 02)\n",
    "- create and run an experiment by using the Azure Machine Learning SDK\n",
    "- consume data from a data store in an experiment by using the Azure Machine Learning SDK\n",
    "- consume data from a dataset in an experiment by using the Azure Machine Learning SDK\n",
    "- choose an estimator for a training experiment\n",
    "\n",
    "#### Generate metrics from an experiment run (Lab 01)\n",
    "- log metrics from an experiment run\n",
    "- retrieve and view experiment outputs\n",
    "- use logs to troubleshoot experiment run errors\n",
    "\n",
    "#### Automate the model training process (Lab 05)\n",
    "- create a pipeline by using the SDK\n",
    "- pass data between steps in a pipeline\n",
    "- run a pipeline\n",
    "- monitor pipeline runs\n",
    "\n",
    "### Optimize and Manage Models (20-25%)\n",
    "\n",
    "#### Use Automated ML to create optimal models (Lab 09)\n",
    "- use the Automated ML interface in Azure Machine Learning studio\n",
    "- use Automated ML from the Azure Machine Learning SDK\n",
    "- select scaling functions and pre-processing options\n",
    "- determine algorithms to be searched\n",
    "- define a primary metric\n",
    "- get data for an Automated ML run\n",
    "- retrieve the best model\n",
    "\n",
    "#### Use Hyperdrive to tune hyperparameters (Lab 08)\n",
    "- select a sampling method\n",
    "- define the search space\n",
    "- define the primary metric \n",
    "- define early termination options\n",
    "- find the model that has optimal hyperparameter values\n",
    "\n",
    "#### Use model explainers to interpret models (Lab 10)\n",
    "- select a model interpreter\n",
    "- generate feature importance data\n",
    "\n",
    "#### Manage models (Lab 02)\n",
    "- register a trained model\n",
    "- monitor model history\n",
    "- monitor data drift\n",
    "\n",
    "### Deploy and Consume Models (20-25%)\n",
    "\n",
    "#### Create production compute targets (Lab 06)\n",
    "- consider security for deployed services\n",
    "- evaluate compute options for deployment\n",
    "\n",
    "#### Deploy a model as a service (Lab 06)\n",
    "- configure deployment settings\n",
    "- consume a deployed service\n",
    "- troubleshoot deployment container issues\n",
    "\n",
    "#### Create a pipeline for batch inferencing (Lab 07)\n",
    "- publish a batch inferencing pipeline\n",
    "- run a batch inferencing pipeline and obtain outputs\n",
    "\n",
    "#### Publish a designer pipeline as a web service (Lab 06)\n",
    "- create a target compute resource\n",
    "- configure an Inference pipeline\n",
    "- consume a deployed endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 Getting Started with Azure Machine Learning\n",
    "\n",
    "The Azure ML SDK for Python provides classes you can use to work with Azure ML in your Azure subscription.\n",
    "\n",
    "### azureml-core package\n",
    "**High level process:**\n",
    "1. **create a new <font color='blue'>*workspace*</font> or connect to an existing workspace** \n",
    "2. **create an Azure ML <font color='blue'>*experiment*</font> in workspace**\n",
    "3. **create a <font color='blue'>*run*</font> to run codes**\n",
    "\n",
    "#### Workspace \n",
    "\n",
    "A **workspace** is a context for the **experiments, data, compute targets, and other assets** associated with **a machine learning workload**. Workspaces are Azure resources, and as such they are defined within a resource group in an Azure subscription, along with other related Azure resources that are required to support the workspace. A Workspace is a fundamental **resource** for machine learning in Azure Machine Learning. You use a workspace to **experiment, train, and deploy machine learning models**.\n",
    "\n",
    "```python\n",
    "from azureml.core import Workspace\n",
    "```\n",
    "- All experiments and associated resources are managed within you Azure ML workspace. You can connect to an existing workspace,  create a new one using the Azure ML SDK, or load the workspace from the configuration file.\n",
    "\n",
    "```python\n",
    "# Load an existing workspace\n",
    "ws = Workspace.get(name=\"myworkspace\", subscription_id='<azure-subscription-id>', resource_group='myresourcegroup')\n",
    "\n",
    "# Create a new one\n",
    "ws = Workspace.create(name='myworkspace',\n",
    "                      subscription_id='<azure-subscription-id>',\n",
    "                      resource_group='myresourcegroup',\n",
    "                      create_resource_group=True,\n",
    "                      location='eastus2'\n",
    "                     )\n",
    "\n",
    "# Load from a configuration file\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "```\n",
    "\n",
    "- In most cases, you should store the workspace configuration in a JSON configuration file. This makes it easier to reconnect without needing to remember details like your Azure subscription ID.\n",
    "\n",
    "```python\n",
    "ws.write_config(path=\"./file-path\", file_name=\"ws_config.json\")\n",
    "```\n",
    "\n",
    "- You can download the JSON configuration file from the blade for your workspace in the Azure portal, but ***if you're using a Compute Instance within your workspace, the configuration file has already been downloaded to the root folder.***\n",
    "- `.from_config()` finds and uses the configuration file from the root folder to connect to your workspace.\n",
    "\n",
    "```python\n",
    "ws_other_environment = Workspace.from_config(path=\"./file-path/ws_config.json\")\n",
    "```\n",
    "\n",
    "#### Experiment\n",
    "\n",
    "In Azure Machine Learning, an **experiment** is a **named process**, usually the running of a script or a pipeline, that can generate metrics and outputs and be tracked in the Azure Machine Learning workspace. An experiment can be run multiple times, with different data, code, or settings; and Azure Machine Learning tracks each run, enabling you to view run history and compare results for each run.\n",
    "\n",
    "When you submit an experiment, you use its run context to initialize and end the experiment run that is tracked in Azure Machine Learning\n",
    "\n",
    "```python\n",
    "from azureml.core import Experiment\n",
    "\n",
    "# create an experiment variable\n",
    "experiment = Experiment(workspace=ws, name='test-experiment')\n",
    "\n",
    "# start the experimennt\n",
    "run = experiment.start_logging()\n",
    "\n",
    "# experiment code goes here\n",
    "\n",
    "# end the experiment\n",
    "run.complete()\n",
    "\n",
    "```\n",
    "\n",
    "After the experiment run has completed, you can view the details of the run in the **Experiments** tab in Azure Machine Learning studio.\n",
    "\n",
    "#### Run\n",
    "A run represent a single trial of an experiment.\n",
    "\n",
    "- There are two ways to create run:\n",
    "    1. `experiment.start_logging()` as previous example\n",
    "    2. `azureml.core.Run` to run a experiment script \n",
    "    \n",
    "```python\n",
    "from azureml.core import Run\n",
    "```\n",
    "- Create a separate script from experiment, store it in a folder along with any other files it needs, and then use Azure ML to run the experiment based on the script in the folder.\n",
    "- `Run.get_context()` method to *retrieve the experiment run context when the script is run*.\n",
    "\n",
    "<ins>**After a run object is created, use various `.log*()` methods to log the outputs.**</ins>\n",
    "\n",
    "```python\n",
    "# An experiment script, experiment.py, saved in the experiment_files folder\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Count the rows and log the result\n",
    "row_count = (len(data))\n",
    "run.log('observations', row_count)\n",
    "\n",
    "# Save a sample of the data\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "data.sample(100).to_csv(\"outputs/sample.csv\", index=False, header=True)\n",
    "\n",
    "# Complete the run\n",
    "run.complete()\n",
    "```\n",
    "\n",
    "#### Configuration\n",
    "\n",
    "To run a script as an experiment, you must define a script configuration that defines the script to be run and the Python environment in which to run it. This is implemented by using a **ScriptRunConfig** object.\n",
    "\n",
    "```python\n",
    "from azureml.core import Experiment, ScriptRunConfig\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
    "                                script='experiment.py') \n",
    "\n",
    "# submit the experiment\n",
    "experiment = Experiment(workspace = ws, name = 'my-experiment')\n",
    "run = experiment.submit(config=script_config)\n",
    "run.wait_for_completion(show_output=True)\n",
    "```\n",
    "- Please refer to [previous note] for better understanding\n",
    "\n",
    "### Note: How to create a simple machine learning workflow\n",
    "\n",
    "1. Create a new workflow or load an exsiting workflow\n",
    "2. Create experiment script and save it in the folder along with other files\n",
    "3. Configure the file and submit the experiment\n",
    "\n",
    "### [Lab: Getting Started with Azure Machine Learning](https://github.com/MicrosoftDocs/mslearn-aml-labs/blob/master/labdocs/Lab01.md)\n",
    "\n",
    "- In this lab, we need to create a **workspace** in Azure Portal and then use **Azure Machine Learning studio** to manage the workspace.\n",
    "    - Create a compute instance under the workspace. ***When creating a Compute Instance, a virtual machine is created.***\n",
    "    - The cheapest virtual machine is STANDARD_D2S_V3\n",
    "        - After the compute instance is created, click its **Jupyter link** to open Jupyter Notebooks on the VM.\n",
    "- **[IMPORTANT!!]** When you have finished the lab, **close all Jupyter tabs and *Stop* your compute instance** to avoid incurring unnecessary costs.\n",
    "\n",
    "### MLflow\n",
    "\n",
    "**MLflow** is an open source platform for managing machine learning processes. It's **commonly (but not exclusively) used in Databricks environments** to coordinate experiments and track metrics. In Azure Machine Learning experiments, you can use MLflow to track metrics instead of the native log functionality if you desire.\n",
    "\n",
    "```python\n",
    "import mlflow\n",
    "```\n",
    "- Refer to the notebook codes in official Git-Hub fore more details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 Training Models with Parameters\n",
    "\n",
    "In Azure Machine Learning, you can use a **Run Configuration** and a **Script Run Configuration** to run a script-based experiment that trains a machine learning model. However, depending on the machine learning framework being used and the dependencies it requires, the run configuration may become complex.\n",
    "\n",
    "Azure Machine Learning also provides a higher level abstraction called an Estimator that encapsulates a **run configuration** and a **script configuration** in a single object, and for which there are pre-defined, framework-specific variants that already include the package dependencies for common machine learning frameworks such as *Scikit-Learn, PyTorch, and Tensorflow*.\n",
    "\n",
    "#### Note: \n",
    "- A difference is to replace script_config with estimator (create estimator object and pass it into the config parameter)\n",
    "- The rest of process to run a model with experiments is basically the same. \n",
    "\n",
    "### Steps:\n",
    "#### Create a training script and log key metrics of modeling performance\n",
    "#### Run the script as experiment\n",
    "- Option 1: Use an Estimator\n",
    "\n",
    "```python\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core import Experiment\n",
    "\n",
    "# Create an estimator\n",
    "estimator = Estimator(source_directory='experiment_folder',\n",
    "                      entry_script='training_script.py',\n",
    "                      compute_target='local',\n",
    "                      conda_packages=['scikit-learn']\n",
    "                      )\n",
    "\n",
    "# Create and run an experiment\n",
    "experiment = Experiment(workspace = ws, name = 'training_experiment')\n",
    "run = experiment.submit(config=estimator)\n",
    "```\n",
    "\n",
    "- Option 2: using framewrk-specific estimators\n",
    "\n",
    "```python\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.core import Experiment\n",
    "\n",
    "# Create an estimator\n",
    "estimator = SKLearn(source_directory='experiment_folder',\n",
    "                    entry_script='training_script.py'\n",
    "                    compute_target='local'\n",
    "                    )\n",
    "\n",
    "# Create and run an experiment\n",
    "experiment = Experiment(workspace = ws, name = 'training_experiment')\n",
    "run = experiment.submit(config=estimator)\n",
    "```\n",
    "\n",
    "#### Register the trained model to the workspace\n",
    "\n",
    "Note that **the outputs of the experiment include the trained model file (model.pkl)**. You can register this model in your Azure Machine Learning workspace, making it possible to track model versions and retrieve them later.\n",
    "\n",
    "Model registration enables you to track multiple versions of a model, and retrieve models for ***inferencing (predicting label values from new data)***. When you register a model, you can specify a name, description, tags, framework (such as Scikit-Learn or PyTorch), framework version, custom properties, and other useful metadata. Registering a model with the same name as an existing model automatically creates a new version of the model, starting with 1 and increasing in units of 1.\n",
    "\n",
    "- Option 1: **register** method of **Model** object\n",
    "\n",
    "```python\n",
    "from azureml.core import Model\n",
    "\n",
    "model = Model.register(workspace=ws,\n",
    "                       model_name='classification_model',\n",
    "                       model_path='model.pkl', # local path\n",
    "                       description='A classification model',\n",
    "                       tags={'dept': 'sales'},\n",
    "                       model_framework=Model.Framework.SCIKITLEARN,\n",
    "                       model_framework_version='0.20.3')\n",
    "```\n",
    "\n",
    "- Option 2: reference to the **Run**\n",
    "\n",
    "```python\n",
    "run.register_model( model_name='classification_model',\n",
    "                    model_path='outputs/model.pkl', # run outputs path\n",
    "                    description='A classification model',\n",
    "                    tags={'dept': 'sales'},\n",
    "                    model_framework=Model.Framework.SCIKITLEARN,\n",
    "                    model_framework_version='0.20.3')\n",
    "```\n",
    "\n",
    "#### Viewing registered models\n",
    "```python\n",
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    # Get model name and auto-generated version\n",
    "    print(model.name, 'version:', model.version)\n",
    "```\n",
    "    \n",
    "\n",
    "### Also: using script parameters\n",
    "\n",
    "#### Add argument into script\n",
    "Adding parameters to your script enables you to repeat the same training experiment with different settings\n",
    "To use parameters in a script, you must use a library such as **argparse** to read the arguments passed to the script and assign them to variables.\n",
    "\n",
    "```python\n",
    "import argparse\n",
    "# also import other packages as neccessary\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# Set regularization hyperparameter\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--reg_rate', type=float, dest='reg', default=0.01)\n",
    "args = parser.parse_args()\n",
    "reg = args.reg\n",
    "\n",
    "# Prepare the dataset\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# The rest of the script\n",
    "```\n",
    "\n",
    "#### Passing Script Arguments to an Estimator\n",
    "```python\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.core import Experiment\n",
    "\n",
    "# Configure/create an estimator\n",
    "estimator = SKLearn(source_directory='experiment_folder',\n",
    "                    entry_script='training_script.py',\n",
    "                    script_params = {'--reg_rate': 0.1},\n",
    "                    compute_target='local'\n",
    "                    )\n",
    "\n",
    "# Create and run an experiment\n",
    "experiment = Experiment(workspace = ws, name = 'training_experiment')\n",
    "run = experiment.submit(config=estimator)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side Note: Revisit how to interprete ROC\n",
    "- Y axis calculates True Positive Rate – the base is True (Ex: 80 True instances)\n",
    "- X axis calculates False Positive Rate – the base is False (Ex: 20 False instances)\n",
    "    - If we select True by randomly, the probability of selecting a true or false instance is 0.8 and 0.2. Therefore, TPR and FPR will increase at around the same pace.\n",
    "    - However, if we build a good predictive model, the probability of selecting a true instance should increase, skewing the curve to the top-left. ***The better the capability of the model to predict true positive, the higher the AUC.***\n",
    "\n",
    "#### Don’t confuse the concept of AUC and Accuracy.\n",
    "- AUC shows **the capability of a model to predict true positives**, and each axis has different base.\n",
    "- The base of accuracy includes both true and false instances. It doesn’t take into account the capability of predicting true positives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 Work with Data in Azure Machine Learning\n",
    "\n",
    "### [IMPORTANT NOTE] Datastores are *file locations* while datasets are are *real data*.\n",
    "\n",
    "### Datastores\n",
    "In Azure Machine Learning, ***datastores*** are abstractions for cloud data sources / storage locations.\n",
    "\n",
    "```python\n",
    "from azureml.core import Workspace, Datastore\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Register a new datastore\n",
    "blob_ds = Datastore.register_azure_blob_container(workspace=ws,\n",
    "    datastore_name='blob_data',\n",
    "    container_name='data_container',\n",
    "    account_name='az_store_acct',\n",
    "    account_key='123456abcde789…')    \n",
    "\n",
    "# Get reference to a data score\n",
    "blob_store = Datastore.get(ws, datastore_name='blob_data')\n",
    "default_store = ws.get_default_datastore()\n",
    "ws.set_default_datastore('blob_data')\n",
    "\n",
    "# Working directly with a datastore\n",
    "blob_ds.upload(src_dir='/files',\n",
    "               target_path='/data/files',\n",
    "               overwrite=True, show_progress=True)\n",
    "\n",
    "blob_ds.download(target_path='downloads',\n",
    "                 prefix='/data',\n",
    "                 show_progress=True)\n",
    "```\n",
    "\n",
    "When you want to use a datastore in an experiment script, you must pass a data reference to the script. The data reference is configured for one of the following data access modes: **download, upload, and mount.**\n",
    "\n",
    "```python\n",
    "# Get a data reference\n",
    "data_ref = blob_ds.path('data/files').as_download(path_on_compute='training_data')\n",
    "\n",
    "# Configuration\n",
    "estimator = SKLearn(source_directory='experiment_folder',\n",
    "                    entry_script='training_script.py'\n",
    "                    compute_target='local',\n",
    "                    script_params = {'--data_folder': data_ref})\n",
    "```\n",
    "\n",
    "In your training script, you ca nretrieve the parameter and use it like a local folder:\n",
    "```python\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data_folder', type=str, dest='data_folder')\n",
    "args = parser.parse_args()\n",
    "data_files = os.listdir(args.data_folder)\n",
    "```\n",
    "\n",
    "### Datasets\n",
    "***Datasets*** are versioned packaged data objects that can be easily consumed in experiments and pipelines. Datasets are the recommended way to work with data, and are the primary mechanism for advanced Azure Machine Learning capabilities like data labeling and data drift monitoring.\n",
    "\n",
    "Datasets are typically based on **files in a datastore**, though they can also be based on URLs and other sources. You can create the following types of dataset: **tabular and file**.\n",
    "\n",
    "```python\n",
    "# Create - Type 1: Creating and registering tabular datasets\n",
    "from azureml.core import Dataset\n",
    "\n",
    "blob_ds = ws.get_default_datastore()\n",
    "\n",
    "    # The dataset in this example includes data from two file paths within the default datastore\n",
    "csv_paths = [(blob_ds, 'data/files/current_data.csv'),\n",
    "             (blob_ds, 'data/files/archive/*.csv')]\n",
    "tab_ds = Dataset.Tabular.from_delimited_files(path=csv_paths)\n",
    "\n",
    "    # After creating the dataset, the code registers it in the workspace with the name csv_table.\n",
    "tab_ds = tab_ds.register(workspace=ws, name='csv_table')\n",
    "\n",
    "# Create - Type 2: Creating and registering file datasets\n",
    "file_ds = Dataset.File.from_files(path=(blob_ds, 'data/files/images/*.jpg'))\n",
    "file_ds = file_ds.register(workspace=ws, name='img_files')\n",
    "\n",
    "# Retrieve a registered dataset\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "    # Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "    # Get a dataset from the workspace datasets collection (dictionary attribute)\n",
    "ds1 = ws.datasets['csv_table']\n",
    "\n",
    "    # Get a dataset by name from the datasets class (method)\n",
    "ds2 = Dataset.get_by_name(ws, 'img_files')\n",
    "\n",
    "# Dataset versioning - specifying the create_new_version property\n",
    "img_paths = [(blob_ds, 'data/files/images/*.jpg'),\n",
    "             (blob_ds, 'data/files/images/*.png')]\n",
    "file_ds = Dataset.File.from_files(path=img_paths)\n",
    "file_ds = file_ds.register(workspace=ws, name='img_files', create_new_version=True)\n",
    "\n",
    "# Retrieving a specific dataset version\n",
    "img_ds = Dataset.get_by_name(workspace=ws, name='img_files', version=2)\n",
    "```\n",
    "\n",
    "You can read data directly from a dataset, or you can pass a dataset as a named input to a script configuration or estimator.\n",
    "```python\n",
    "# Working with a dataset directly\n",
    "    # Tabuler\n",
    "df = tab_ds.to_pandas_dataframe()\n",
    "# code to work with dataframe goes here\n",
    "\n",
    "    # File\n",
    "for file_path in file_ds.to_path():\n",
    "    print(file_path)\n",
    "```\n",
    "\n",
    "When you need to access a dataset in an experiment script, you can pass the dataset as an input to a **ScriptRunConfig** or an **Estimator**. For example, the following code passes a tabular dataset to an estimator:\n",
    "\n",
    "Since the script will need to work with a Dataset object, you must include either **the full azureml-sdk package** or **the azureml-dataprep package with the pandas extra library** in the script's compute environment.\n",
    "\n",
    "```python\n",
    "estimator = SKLearn( source_directory='experiment_folder',\n",
    "                     entry_script='training_script.py',\n",
    "                     compute_target='local',\n",
    "                     inputs=[tab_ds.as_named_input('csv_data')],\n",
    "                     pip_packages=['azureml-dataprep[pandas]')\n",
    "```\n",
    "\n",
    "In the experiment script itself, you can access the input and work with the Dataset object it references like this:\n",
    "\n",
    "```python\n",
    "run = Run.get_context()\n",
    "data = run.input_datasets['csv_data'].to_pandas_dataframe()\n",
    "```\n",
    "\n",
    "When passing a file dataset, you must **specify the access mode**. For large volumes of data, you'd generally use the **as_mount** method to stream the files directly from the dataset source; but when running on local compute (as we are in this example), you need to use the **as_download** option to download the dataset files to a local folder.\n",
    "\n",
    "```python\n",
    "estimator = Estimator( source_directory='experiment_folder',\n",
    "                     entry_script='training_script.py'\n",
    "                     compute_target='local',\n",
    "                     inputs=[img_ds.as_named_input('img_data').as_download(path_on_compute='data')],\n",
    "                     pip_packages=['azureml-dataprep[pandas]')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 Work with Compute in Azure machine Learning\n",
    "The runtime context for each experiment run consists of two elements:\n",
    "1. The *environment* for the script, which includes all packages used in the script.\n",
    "2. The *compute target* on which the environment will be deployed and the script run. This could be the local workstation from which the experiment run is initiated, or a remote compute target such as a training cluster that is provisioned on-demand.\n",
    "    - In Azure Machine Learning, *Compute Targets* are **physical or virtual computers on which experiments are run.\n",
    "\n",
    "When you run a Python script as an experiment in Azure Machine Learning, a Conda environment is created to define the execution context for the script. Azure Machine Learning provides a default environment that includes many common packages; including the **azureml-defaults** package that contains the libraries necessary for working with an experiment run, as well as popular packages like **pandas** and **numpy**.\n",
    "\n",
    "\n",
    "You can also define your own environment and add packages by using **conda** or **pip**, to ensure your experiment has access to all the libraries it requires.\n",
    "```python\n",
    "estimator = Estimator (source_directory=experiment_folder,\n",
    "                       inputs=[diabetes_ds.as_named_input('diabetes')],\n",
    "                       script_params=script_params,\n",
    "                       compute_target = 'local', # OR compute_target = cluster_name # Run on the remote compute target\n",
    "                       environment_definition = diabetes_env, # environment\n",
    "                       entry_script='diabetes_training.py')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05 Orchestra machine learning with pipelines\n",
    "\n",
    "### Definition\n",
    "The term pipeline is used extensively in machine learning, often with different meanings.\n",
    "- Scikit-Learn pipeline\n",
    "- Azure Machine Learning pipelines: a workflow of machine learning tasks in which each task is implemented as a *step*. **Check bookmark: Introduction to Pipelines**\n",
    "- Azure DevOps pipelines: the build and configuration tasks required to deliver software.\n",
    "\n",
    "### Key objects for building a pipeline\n",
    "- Steps\n",
    "```python\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "```\n",
    "    - A pipeline is like an experiment, and each step is like a part of the experiment. \n",
    "- PipelineData\n",
    "```python\n",
    "from azureml.pipeline.core import PipelineData\n",
    "```\n",
    "    - To use a PipelineData object to pass data between steps, you must:\n",
    "        - Define a named PipelineData object that references **a location** in a datastore. **(BIG NOTE: The PipelineData is only a reference to a location. It is NOT a dataset.)**\n",
    "        - Specify the PipelineData object as an input or output for the steps that use it.\n",
    "        - Pass the PipelineData object as **a script parameter** in steps that run scripts (and include code in those scripts to read or write data)**(Note: Specify the location parameter in script.)**\n",
    "- Pipeline\n",
    "```python\n",
    "from azureml.pipeline.core import Pipeline\n",
    "```\n",
    "\n",
    "### [Pattern for creating and using pipelines](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py#pattern-for-creating-and-using-pipelines)\n",
    "\n",
    "- **A Azure Machine learning Pipeline is associated with an <ins>Azure Machine Learning workspace</ins>.**\n",
    "- **A pipeline step is associated with a <ins>compute target</ins> within that workspace.**\n",
    "\n",
    "A common pattern for pipeline steps is:\n",
    "\n",
    "1. Specify workspace, compute, and storage\n",
    "2. Configure your input and output data using\n",
    "    - Dataset which makes available an existing Azure datastore\n",
    "    - PipelineDataset which encapsulates typed tabular data\n",
    "    - PipelineData which is used for intermediate file or directory data written by one step and intended to be consumed by another\n",
    "3. Define one or more pipeline steps\n",
    "4. Instantiate a pipeline using your workspace and steps\n",
    "5. Create an experiment to which you submit the pipeline\n",
    "6. Monitor the experiment results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06 Deploy real-time machine learning services with Azure Machine Learning\n",
    "In machine learning, *inferencing* refers to the use of a trained model to predict labels for new data on which the model has not been trained. In Azure Machine learning, you can create **real-time inferencing solutions by deploying a model as a service**, hosted in a **containerized platform** such as **Azure Kubernetes Services (AKS)**.\n",
    "\n",
    "**Notes:** \n",
    "- **We can also deploy the model on Azure Container Instances (ACI) Web Service or local Docker-based service during development and testing.**\n",
    "- **ACI web service is best for small scale testing and quick deployments, and AKS is for deloyments as a production-scale web service.**\n",
    "\n",
    "To deploy a model as a real-time inferencing service, you must perform the following tasks:\n",
    "1.\tRegister a trained model\n",
    "2.\tDefine an inference configuration\n",
    "    1.\tCreate an **entry script**: The entry script receives data submitted to a deployed web service and passes it to the model. It then takes the response returned by the model and returns that to the client. *The script is specific to your model.* It must understand the data that the model expects and returns.\n",
    "        1.\t`init()`: Called when the service is initialized - Typically, this function loads the model into a global object. This function is run only once, when the Docker container for your web service is started.\n",
    "        2.\t`run(inpute_data)`: Called with new data is submitted to the service - This function uses the model to predict a value based on the input data. Inputs and outputs of the run typically use JSON for serialization and deserialization. You can also work with raw binary data. You can transform the data before sending it to the model or before returning it to the client.\n",
    "\n",
    "            ```python\n",
    "            [To include entry script codes]\n",
    "            ```\n",
    "        \n",
    "    2.\tCreate an environment\n",
    "    3.\tCombine the script and environment in an InferenceConfig\n",
    "\n",
    "    ```python\n",
    "    from azureml.core.model import InferenceConfig\n",
    "\n",
    "    classifier_inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                                  source_directory = 'service_files',\n",
    "                                                  entry_script=\"score.py\",\n",
    "                                                  conda_file=\"env.yml\")\n",
    "    ```\n",
    "\n",
    "3.\tDefine a deployment configuration on the chosen compute target\n",
    "    - AksCompute\n",
    "    ```python\n",
    "    from azureml.core.compute import ComputeTarget, AksCompute\n",
    "    from azureml.core.webservice import AksWebservice\n",
    "    ```\n",
    "\n",
    "    - ACI deployment\n",
    "    ```python\n",
    "    from azureml.core.webservice import AciWebservice\n",
    "    ```\n",
    "    \n",
    "    - local Docker-based service\n",
    "    ```python\n",
    "    from azureml.core.webservice import LocalWebservice\n",
    "    ```\n",
    "4.\tDeploy the model\n",
    "```python\n",
    "service = Model.deploy(workspace=ws,\n",
    "                       name = 'classifier-service',\n",
    "                       models = [model], #1. Model registered\n",
    "                       inference_config = classifier_inference_config, # 2. Inference Configuration\n",
    "                       deployment_config = classifier_deploy_config, # 3. deployment configuration\n",
    "                       deployment_target = production_cluster) # (Optional) 3. deployment configuration\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)\n",
    "```\n",
    "\n",
    "To delete a deployed web service, use `service.delete()`. To delete a registered model, use `model.delete()`.\n",
    "\n",
    "#### [Additional Topic: Create an endpoint](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-azure-kubernetes-service#create-an-endpoint)\n",
    "\n",
    "**To create an endpoint, use `AksEndpoint.deploy_configuration` instead of `AksWebservice.deploy_configuration()`.**\n",
    "\n",
    "```python\n",
    "import azureml.core,\n",
    "from azureml.core.webservice import AksEndpoint\n",
    "from azureml.core.compute import AksCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "# select a created compute\n",
    "compute = ComputeTarget(ws, 'myaks')\n",
    "namespace_name= endpointnamespace\n",
    "# define the endpoint and version name\n",
    "endpoint_name = \"mynewendpoint\"\n",
    "version_name= \"versiona\"\n",
    "# create the deployment config and define the scoring traffic percentile for the first deployment\n",
    "endpoint_deployment_config = AksEndpoint.deploy_configuration(cpu_cores = 0.1, memory_gb = 0.2,\n",
    "                                                              enable_app_insights = True,\n",
    "                                                              tags = {'sckitlearn':'demo'},\n",
    "                                                              description = \"testing versions\",\n",
    "                                                              version_name = version_name,\n",
    "                                                              traffic_percentile = 20)\n",
    " # deploy the model and endpoint\n",
    " endpoint = Model.deploy(ws, endpoint_name, [model], inference_config, endpoint_deployment_config, compute)\n",
    " # Wait for he process to complete\n",
    " endpoint.wait_for_deployment(True)\n",
    "```\n",
    "\n",
    "To *consume* a deployed real-time service (or model or endpoint), we’ll need the following: **(Note: Recall the consume tab in AML Studio.)**\n",
    "-\tHTTP Post/ Url **(Note: Recall the step to copy the REST url on AML studio and paste it in the script.)**\n",
    "-\tKey **(Note: Recall the step to copy the primary key on AML studio and paste it in the script.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07 Deploy batch inference pipelines with Azure Machine Learning\n",
    "The steps are not very consistent between lectures and lab codes. Refer to the lab codes when there’s inconsistency.\n",
    "1.\tRegister a model\n",
    "2.\tCreate a scoring script and define a run context that includes the dependencies required by the script\n",
    "3.\tCreate a pipeline with **ParallelRunStep** (As the chapter name suggests, we’re going to create a step in pipeline)\n",
    "```python\n",
    "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\n",
    "# Define the parallel run step step configuration\n",
    "# Create the parallel run step\n",
    "```\n",
    "4.\tRun the pipeline and retrieve the step output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08 Tune hyperparameters with Azure Machine Learning\n",
    "For a discrete parameter, use a **choice** from a list of explicit values. Example: `'--batch_size': choice(16, 32, 64)`\n",
    "### Type of sampling:\n",
    "- Grid sampling\n",
    "- Random sampling\n",
    "- Bayesian sampling\n",
    "\n",
    "### Early termination\n",
    "- Bandit policy: stop a run if the target performance metric underperforms the best run so far by a specified margin\n",
    "```python\n",
    "from azureml.train.hyperdrive import BanditPolicy\n",
    "```\n",
    "- Median stopping policy: abandons runs where the target performance metric is worse than the median of the running averages for all runs\n",
    "```python\n",
    "from azureml.train.hyperdrive import MedianStoppingPolicy\n",
    "```\n",
    "- Truncation selection policy: cancels the lowest performing X% of runs at each evaluation interval based on the truncation_percentage value you specify for X\n",
    "```python\n",
    "from azureml.train.hyperdrive import TruncationSelectionPolicy\n",
    "```\n",
    "\n",
    "### Running a hyperparameter tuning experiment\n",
    "- Create a training script that\n",
    "    - Includes an argument for each hyperparameter you want to vary (covered in previous lab)\n",
    "    - Log the target performance metric (covered in previous lab)\n",
    "- Configure and run hyperdrive experiment\n",
    "```python\n",
    "from azureml.train.hyperdrive import HyperDriveConfig, PrimaryMetricGoal\n",
    "```\n",
    "- Monitor and review hyperdrive runs \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09 Automate machine learning model selection with Azure Machine Learning\n",
    "Automated Machine Learning is one of the two big features, Automated ML and Designer, in AML studio. You can use the visual interface in Azure Machine Learning studio or the SDK to leverage this capability. The SDK gives you greater control over the settings for the automated machine learning experiment, but the visual interface is easier to use.\n",
    "\n",
    "Configure an Automated Machine Learning experiment: \n",
    "```python\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Explain machine learning models with Azure Machine Learning\n",
    "\n",
    "### Type of Feature Importance\n",
    "- **Global feature importance** quantifies the relative importance of each feature in the test dataset as a whole.\n",
    "- **Local feature importance** measures the influence of each feature value for a specific individual prediction.\n",
    "\n",
    "### Explainers\n",
    "Using explainers – install the **azureml-interpret** package\n",
    "- MimicExplainer – An explainer that creates a *global surrogate model* that approximates your trained model and can be used to generate explanations.\n",
    "```python\n",
    "from interpret.ext.blackbox import MimicExplainer\n",
    "from interpret.ext.glassbox import DecisionTreeExplainableModel # Requires most arguments\n",
    "```\n",
    "- TabularExplainer – An explainer that acts as a wrapper around various SHAP explainer algorithms, automatically choosing the one that is most appropriate for your model architecture.\n",
    "```python\n",
    "from interpret.ext.blackbox import TabularExplainer # Does not require explainable_model\n",
    "```\n",
    "- PFIExplainer – a *Permutation Feature Importance* explainer that analyzes feature importance by shuffling feature values and measuring the impact on prediction performance.\n",
    "```python\n",
    "from interpret.ext.blackbox import PFIExplainer #Does not require explainable_model and initialization_example\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 Detect and mitigate unfairness in models with Azure Machine Learning\n",
    "\n",
    "### Disparity\n",
    "[To add more notes]\n",
    "\n",
    "\n",
    "A model with lower disparity in predictive performance between sensitive feature groups might be favorable then the model with higher disparity and overall accuracy.\n",
    "\n",
    "#### Side Note – under what situations we might choose a model with lower accuracy/AUC over a higher one?\n",
    "- Time required for training\n",
    "- Interpretability\n",
    "- Lower disparity between sensitive feature groups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 Monitor a Model\n",
    "To capture telemetry data for Application insights, you can write any values to the standard output log in the scoring script for your service by using a print statement\n",
    "\n",
    "Summarize the whole workflow from building, deploying, consuming, to monitoring a model.\n",
    "- Refer to Jupyter Notebook for the complete codes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
