{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study Note - Building AI Solutions with Azure Machine Learning\n",
    "This notebook collects the notes taken through the course of **[Build AI solutions with Azure Machine Learning](https://docs.microsoft.com/en-us/learn/paths/build-ai-solutions-with-azure-ml-service/)** offered by Microsoft, with supplements from the **[documentation of Azure Machine Learning SDK for Python](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py)**.\n",
    "\n",
    "This notebook contains Labs 08 - 13 of the learning course, which correspond to \"Optimize and Manage Models\" section in the exam guideline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08 Tune hyperparameters with Azure Machine Learning\n",
    "For a discrete parameter, use a **choice** from a list of explicit values. Example: `'--batch_size': choice(16, 32, 64)`\n",
    "### Type of sampling:\n",
    "- Grid sampling\n",
    "- Random sampling\n",
    "- Bayesian sampling\n",
    "\n",
    "### Early termination\n",
    "- Bandit policy: stop a run if the target performance metric underperforms the best run so far by a specified margin\n",
    "```python\n",
    "from azureml.train.hyperdrive import BanditPolicy\n",
    "```\n",
    "- Median stopping policy: abandons runs where the target performance metric is worse than the median of the running averages for all runs\n",
    "```python\n",
    "from azureml.train.hyperdrive import MedianStoppingPolicy\n",
    "```\n",
    "- Truncation selection policy: cancels the lowest performing X% of runs at each evaluation interval based on the truncation_percentage value you specify for X\n",
    "```python\n",
    "from azureml.train.hyperdrive import TruncationSelectionPolicy\n",
    "```\n",
    "\n",
    "### Running a hyperparameter tuning experiment\n",
    "- Create a training script that\n",
    "    - Includes an argument for each hyperparameter you want to vary (covered in previous lab)\n",
    "    - Log the target performance metric (covered in previous lab)\n",
    "- Configure and run hyperdrive experiment\n",
    "```python\n",
    "from azureml.train.hyperdrive import HyperDriveConfig, PrimaryMetricGoal\n",
    "```\n",
    "- Monitor and review hyperdrive runs \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09 Automate machine learning model selection with Azure Machine Learning\n",
    "Automated Machine Learning is one of the two big features, Automated ML and Designer, in AML studio. You can use the visual interface in Azure Machine Learning studio or the SDK to leverage this capability. The SDK gives you greater control over the settings for the automated machine learning experiment, but the visual interface is easier to use.\n",
    "\n",
    "Configure an Automated Machine Learning experiment: \n",
    "```python\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Explain machine learning models with Azure Machine Learning\n",
    "\n",
    "### Type of Feature Importance\n",
    "- **Global feature importance** quantifies the relative importance of each feature in the test dataset as a whole.\n",
    "- **Local feature importance** measures the influence of each feature value for a specific individual prediction.\n",
    "\n",
    "### Explainers\n",
    "Using explainers – install the **azureml-interpret** package\n",
    "- MimicExplainer – An explainer that creates a *global surrogate model* that approximates your trained model and can be used to generate explanations.\n",
    "```python\n",
    "from interpret.ext.blackbox import MimicExplainer\n",
    "from interpret.ext.glassbox import DecisionTreeExplainableModel # Requires most arguments\n",
    "```\n",
    "- TabularExplainer – An explainer that acts as a wrapper around various SHAP explainer algorithms, automatically choosing the one that is most appropriate for your model architecture.\n",
    "```python\n",
    "from interpret.ext.blackbox import TabularExplainer # Does not require explainable_model\n",
    "```\n",
    "- PFIExplainer – a *Permutation Feature Importance* explainer that analyzes feature importance by shuffling feature values and measuring the impact on prediction performance.\n",
    "```python\n",
    "from interpret.ext.blackbox import PFIExplainer #Does not require explainable_model and initialization_example\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 Detect and mitigate unfairness in models with Azure Machine Learning\n",
    "\n",
    "### Disparity\n",
    "[To add more notes]\n",
    "\n",
    "\n",
    "A model with lower disparity in predictive performance between sensitive feature groups might be favorable then the model with higher disparity and overall accuracy.\n",
    "\n",
    "#### Side Note – under what situations we might choose a model with lower accuracy/AUC over a higher one?\n",
    "- Time required for training\n",
    "- Interpretability\n",
    "- Lower disparity between sensitive feature groups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 Monitor a Model\n",
    "To capture telemetry data for Application insights, you can write any values to the standard output log in the scoring script for your service by using a print statement\n",
    "\n",
    "Summarize the whole workflow from building, deploying, consuming, to monitoring a model.\n",
    "- Refer to Jupyter Notebook for the complete codes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
