{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study Note - Azure Machine Learning Introduction and Designer Interface\n",
    "This notebook collects notes taken during the course **[Introduction to the Azure Machine Learning SDK](https://docs.microsoft.com/en-us/learn/modules/intro-to-azure-machine-learning-service/)** and **[Create no-code predictive models with Azure Machine Learning](https://docs.microsoft.com/en-us/learn/paths/create-no-code-predictive-models-azure-machine-learning/)** offered by Microsoft, as well as documentations of Azure from Microsoft."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Machine Learning tools and interfaces\n",
    "\n",
    "Azure Machine Learning (Azure ML) is a **cloud-based service** for **creating and managing machine learning solutions**. It's designed to help data scientists leverage their existing data processing and model development skills and frameworks, and help them **scale their workloads to the cloud**. The Azure ML SDK for Python provides classes you can use to work with Azure ML in your Azure subscription.\n",
    "\n",
    "### Interfaces\n",
    "#### Azure Machine Learning studio\n",
    "A web-based tool for managing an Azure Machine Learning workspace. It enables you to create, manage, and view all of the assets in your workspace and provides the following graphical tools:\n",
    "- Designer\n",
    "- Automated Machine Learning\n",
    "\n",
    "#### The Azure Machine Learning SDK\n",
    "- Documentation: https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Using Azure Machine Learning: Workspace -> Experiment -> Run\n",
    "### [Workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace)\n",
    "The workspace is ***the top-level resource*** for Azure Machine Learning, providing **a centralized place to work with all the artifacts you create when you use Azure Machine Learning**.\n",
    "\n",
    "#### Machine learning tasks read and/or write artifacts to your workspace.\n",
    "\n",
    "- **Run an experiment** to train a model - writes experiment run results to the workspace.\n",
    "- Use **automated ML** to train a model - writes training results to the workspace.\n",
    "- **Register a model** in the workspace.\n",
    "- **Deploy a model** - uses the registered model to create a deployment.\n",
    "- Create and run **reusable workflows**.\n",
    "- **View machine learning artifacts** such as experiments, pipelines, models, deployments.\n",
    "- Track and **monitor models**.\n",
    "\n",
    "\n",
    "### Run an Experiment\n",
    "\n",
    "In Azure Machine Learning, an experiment is **a named process**, usually **the running of a script or a pipeline**, that can generate metrics and outputs and be tracked in the Azure Machine Learning workspace.\n",
    "\n",
    "An experiment can be run multiple times, with different data, code, or settings; and Azure Machine Learning tracks each run, enabling you to view run history and compare results for each run.\n",
    "\n",
    "When you submit an experiment, you use its run context to initialize and end the experiment run that is tracked in Azure Machine Learning, as shown in the following code sample:\n",
    "from azureml.core import Experiment\n",
    "```python\n",
    "# create an experiment variable\n",
    "experiment = Experiment(workspace = ws, name = \"my-experiment\")\n",
    "\n",
    "# start the experiment\n",
    "run = experiment.start_logging()\n",
    "\n",
    "# experiment code goes here\n",
    "\n",
    "# end the experiment\n",
    "run.complete()\n",
    "```\n",
    "\n",
    "<ins>Running a Script as an Experiment</ins>\n",
    "\n",
    "You can run an experiment inline using the start_logging method of the Experiment object, but it's more common to encapsulate the experiment logic in a script and run the script as an experiment.\n",
    "\n",
    "To access the experiment run context (which is needed to log metrics) the script must import the **azureml.core.Run** class and call its **get_context** method. The script can then use the run context to log metrics, upload files, and complete the experiment, as shown in the following example:\n",
    "```python\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Count the rows and log the result\n",
    "row_count = (len(data))\n",
    "run.log('observations', row_count)\n",
    "\n",
    "# Save a sample of the data\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "data.sample(100).to_csv(\"outputs/sample.csv\", index=False, header=True)\n",
    "\n",
    "# Complete the run\n",
    "run.complete()\n",
    "```\n",
    "\n",
    "To run a script as an experiment, you must define \n",
    "- a *run configuration* that defines the Python environment in which the script will be run, and \n",
    "- a *script run configuration* that associates the run environment with the script. \n",
    "These are implemented by using the **RunConfiguration** and **ScriptRunConfig** objects.\n",
    "\n",
    "For example, the following code could be used to run an experiment based on a script in the **experiment_files** folder (which must also contain any files used by the script, such as the data.csv file in previous script code example):\n",
    "\n",
    "```python\n",
    "from azureml.core import Experiment, RunConfiguration, ScriptRunConfig\n",
    "\n",
    "# create a new RunConfig object\n",
    "experiment_run_config = RunConfiguration()\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory=experiment_folder, \n",
    "                                script='experiment.py',\n",
    "                                run_config=experiment_run_config) \n",
    "\n",
    "# submit the experiment\n",
    "experiment = Experiment(workspace = ws, name = 'my-experiment')\n",
    "run = experiment.submit(config=script_config)\n",
    "run.wait_for_completion(show_output=True)\n",
    "```\n",
    "\n",
    "The **RunConfiguration** object defines the Python environment for the experiment, including the packages available to the script. If your script depends on packages that are not included in the default environment, you must associate the **RunConfiguration** with an Environment object that makes use of a **CondaDependencies** object to specify the Python packages required.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Machine Learning Designer\n",
    "-\tScore Data module is like `.predict()` function in Python packages\n",
    "\n",
    "### The process of building ML workflow on Azure\n",
    "1.\tCreate a dataset\n",
    "2.\tBuild model pipeline on compute cluster\n",
    "    - Data transformation\n",
    "    - Train/test different models here\n",
    "3.\tCreate inference pipeline on inference cluster (Real-time inference pipeline or Batch inference pipeline):\n",
    "    - Remove original dataset & test with manual input\n",
    "    - Add Python script to only keep columns needed after deployment (This step is not required for clustering.)\n",
    "4.\tDeploy the model to an Azure Kubernetes Service (AKS) cluster\n",
    "    - Set up a new real-time endpoint on the cluster\n",
    "    - Get the REST endpoint and Primary Key of the service\n",
    "    - Use the REST endpoint and Primary Key to connect to application that reads new data (Need real example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
